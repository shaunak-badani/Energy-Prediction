{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Preprocessed MD17 as HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchani\n",
    "import os\n",
    "import math\n",
    "import torch.utils.tensorboard\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle():\n",
    "    f = open('model_config', 'rb')     \n",
    "    cfg = pickle.load(f)\n",
    "    f.close()\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    path = os.path.dirname(os.path.realpath(__file__))\n",
    "except NameError:\n",
    "    path = os.getcwd()\n",
    "dspath = os.path.join(path, \"{}.h5\".format(cfg['name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchani.data.load(dspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training own neural network potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to convert energy unit from Hartree to kcal/mol\n",
    "from torchani.units import hartree2kcalmol\n",
    "\n",
    "# device to run the training\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "batch_size = 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model_Hyperparameters import get_aev_params, get_complete_network\n",
    "energy_shifter, aev_computer = get_aev_params(device)\n",
    "H_network,C_network, N_network, O_network, model, nn = get_complete_network(aev_computer, device, return_networks = True)\n",
    "species_order = ['H', 'C', 'N', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self atomic energies:  tensor([-19.4591, -19.4591], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "training, validation = data.subtract_self_energies(energy_shifter, species_order).species_to_indices(species_order).shuffle().split(0.8, None)\n",
    "training = training.collate(batch_size).cache()\n",
    "validation = validation.collate(batch_size).cache()\n",
    "print('Self atomic energies: ', energy_shifter.self_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANIModel(\n",
       "  (0): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=160, bias=True)\n",
       "    (1): CELU(alpha=0.1)\n",
       "    (2): Linear(in_features=160, out_features=128, bias=True)\n",
       "    (3): CELU(alpha=0.1)\n",
       "    (4): Linear(in_features=128, out_features=96, bias=True)\n",
       "    (5): CELU(alpha=0.1)\n",
       "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=144, bias=True)\n",
       "    (1): CELU(alpha=0.1)\n",
       "    (2): Linear(in_features=144, out_features=112, bias=True)\n",
       "    (3): CELU(alpha=0.1)\n",
       "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
       "    (5): CELU(alpha=0.1)\n",
       "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
       "    (1): CELU(alpha=0.1)\n",
       "    (2): Linear(in_features=128, out_features=112, bias=True)\n",
       "    (3): CELU(alpha=0.1)\n",
       "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
       "    (5): CELU(alpha=0.1)\n",
       "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
       "    (1): CELU(alpha=0.1)\n",
       "    (2): Linear(in_features=128, out_features=112, bias=True)\n",
       "    (3): CELU(alpha=0.1)\n",
       "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
       "    (5): CELU(alpha=0.1)\n",
       "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_params(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight, a=1.0)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "nn.apply(init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdamW = torch.optim.AdamW([\n",
    "    # H networks\n",
    "    {'params': [H_network[0].weight]},\n",
    "    {'params': [H_network[2].weight], 'weight_decay': 0.00001},\n",
    "    {'params': [H_network[4].weight], 'weight_decay': 0.000001},\n",
    "    {'params': [H_network[6].weight]},\n",
    "    # C networks\n",
    "    {'params': [C_network[0].weight]},\n",
    "    {'params': [C_network[2].weight], 'weight_decay': 0.00001},\n",
    "    {'params': [C_network[4].weight], 'weight_decay': 0.000001},\n",
    "    {'params': [C_network[6].weight]},\n",
    "    # N networks\n",
    "    {'params': [N_network[0].weight]},\n",
    "    {'params': [N_network[2].weight], 'weight_decay': 0.00001},\n",
    "    {'params': [N_network[4].weight], 'weight_decay': 0.000001},\n",
    "    {'params': [N_network[6].weight]},\n",
    "    # O networks\n",
    "    {'params': [O_network[0].weight]},\n",
    "    {'params': [O_network[2].weight], 'weight_decay': 0.00001},\n",
    "    {'params': [O_network[4].weight], 'weight_decay': 0.000001},\n",
    "    {'params': [O_network[6].weight]},\n",
    "])\n",
    "\n",
    "SGD = torch.optim.SGD([\n",
    "    # H networks\n",
    "    {'params': [H_network[0].bias]},\n",
    "    {'params': [H_network[2].bias]},\n",
    "    {'params': [H_network[4].bias]},\n",
    "    {'params': [H_network[6].bias]},\n",
    "    # C networks\n",
    "    {'params': [C_network[0].bias]},\n",
    "    {'params': [C_network[2].bias]},\n",
    "    {'params': [C_network[4].bias]},\n",
    "    {'params': [C_network[6].bias]},\n",
    "    # N networks\n",
    "    {'params': [N_network[0].bias]},\n",
    "    {'params': [N_network[2].bias]},\n",
    "    {'params': [N_network[4].bias]},\n",
    "    {'params': [N_network[6].bias]},\n",
    "    # O networks\n",
    "    {'params': [O_network[0].bias]},\n",
    "    {'params': [O_network[2].bias]},\n",
    "    {'params': [O_network[4].bias]},\n",
    "    {'params': [O_network[6].bias]},\n",
    "], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdamW_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(AdamW, factor=0.5, patience=100, threshold=0)\n",
    "SGD_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(SGD, factor=0.5, patience=100, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_checkpoint = 'latest.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(latest_checkpoint):\n",
    "    checkpoint = torch.load(latest_checkpoint)\n",
    "    nn.load_state_dict(checkpoint['nn'])\n",
    "    AdamW.load_state_dict(checkpoint['AdamW'])\n",
    "    SGD.load_state_dict(checkpoint['SGD'])\n",
    "    AdamW_scheduler.load_state_dict(checkpoint['AdamW_scheduler'])\n",
    "    SGD_scheduler.load_state_dict(checkpoint['SGD_scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    # run validation\n",
    "    mse_sum = torch.nn.MSELoss(reduction='sum')\n",
    "    total_mse = 0.0\n",
    "    count = 0\n",
    "    for properties in validation:\n",
    "        species = properties['species'].to(device)\n",
    "        coordinates = properties['coordinates'].to(device).float()\n",
    "        true_energies = properties['energies'].to(device).float()\n",
    "        _, predicted_energies = model((species, coordinates))\n",
    "        total_mse += mse_sum(predicted_energies, true_energies).item()\n",
    "        count += predicted_energies.shape[0]\n",
    "    return hartree2kcalmol(math.sqrt(total_mse / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = torch.utils.tensorboard.SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training starting from epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 0:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 290.2267235837759 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|██████████| 20/20 [00:32<00:00,  1.63s/it]\n",
      "epoch 1:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 87.35649229945302 at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 20/20 [00:31<00:00,  1.57s/it]\n",
      "epoch 2:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9.467225211770424 at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 20/20 [00:31<00:00,  1.59s/it]\n",
      "epoch 3:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.3988551371198055 at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 20/20 [00:31<00:00,  1.58s/it]\n",
      "epoch 4:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.595786768092899 at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 20/20 [00:31<00:00,  1.55s/it]\n"
     ]
    }
   ],
   "source": [
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "print(\"training starting from epoch\", AdamW_scheduler.last_epoch + 1)\n",
    "max_epochs = 5\n",
    "early_stopping_learning_rate = 1.0E-5\n",
    "best_model_checkpoint = 'best.pt'\n",
    "\n",
    "for _ in range(AdamW_scheduler.last_epoch + 1, max_epochs):\n",
    "    rmse = validate()\n",
    "    print('RMSE:', rmse, 'at epoch', AdamW_scheduler.last_epoch + 1)\n",
    "\n",
    "    learning_rate = AdamW.param_groups[0]['lr']\n",
    "\n",
    "    if learning_rate < early_stopping_learning_rate:\n",
    "        break\n",
    "\n",
    "    # checkpoint\n",
    "    if AdamW_scheduler.is_better(rmse, AdamW_scheduler.best):\n",
    "        torch.save(nn.state_dict(), best_model_checkpoint)\n",
    "\n",
    "    AdamW_scheduler.step(rmse)\n",
    "    SGD_scheduler.step(rmse)\n",
    "\n",
    "    tensorboard.add_scalar('validation_rmse', rmse, AdamW_scheduler.last_epoch)\n",
    "    tensorboard.add_scalar('best_validation_rmse', AdamW_scheduler.best, AdamW_scheduler.last_epoch)\n",
    "    tensorboard.add_scalar('learning_rate', learning_rate, AdamW_scheduler.last_epoch)\n",
    "\n",
    "    for i, properties in tqdm.tqdm(\n",
    "        enumerate(training),\n",
    "        total=len(training),\n",
    "        desc=\"epoch {}\".format(AdamW_scheduler.last_epoch)\n",
    "    ):\n",
    "        species = properties['species'].to(device)\n",
    "        coordinates = properties['coordinates'].to(device).float()\n",
    "        true_energies = properties['energies'].to(device).float()\n",
    "        num_atoms = (species >= 0).sum(dim=1, dtype=true_energies.dtype)\n",
    "        _, predicted_energies = model((species, coordinates))\n",
    "\n",
    "        loss = (mse(predicted_energies, true_energies) / num_atoms.sqrt()).mean()\n",
    "\n",
    "        AdamW.zero_grad()\n",
    "        SGD.zero_grad()\n",
    "        loss.backward()\n",
    "        AdamW.step()\n",
    "        SGD.step()\n",
    "\n",
    "        # write current batch loss to TensorBoard\n",
    "        tensorboard.add_scalar('batch_loss', loss, AdamW_scheduler.last_epoch * len(training) + i)\n",
    "\n",
    "    torch.save({\n",
    "        'nn': nn.state_dict(),\n",
    "        'AdamW': AdamW.state_dict(),\n",
    "        'SGD': SGD.state_dict(),\n",
    "        'AdamW_scheduler': AdamW_scheduler.state_dict(),\n",
    "        'SGD_scheduler': SGD_scheduler.state_dict(),\n",
    "    }, latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done with Training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
